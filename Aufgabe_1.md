# Aufgabe MALIS 21.3 WPM_T9.1: Data Science / Data Librarianship / IT-Praxis
## Beschreibung von datenintensiven und datenfokussierten Aktivitäten im eigenen Arbeitsalltag / in der eigenen Institution
von Sarah Eschmann

### Datenintensive und datenfokussierte Prozesse in der BLB
In der Badischen Landesbibliothek (BLB) werden an vielen Stellen datenintensive Aktivitäten durchgeführt. Da ich jedoch nur in den beiden Bereichen "Pflichtexemplare" und "Teaching Library" einen tieferen Einblick habe, werden einige Aufgaben nur aufgezählt, ohne dass tiefer darauf eingegangen wird.
Ein Beispiel für einen datenintensiven Prozess im Pflichtexemplar-Bereich ist das Auswerten der Neuerscheinungen auf relevante Pflichtexemplare. Hierfür wird das Tool eMAS verwendet, das von der Württembergischen Landesbibliothek programmiert wurde. Das Programm wertet die Neuerscheinungslisten der DNB der Reihen A, B und O mithilfe der Verlagsorte aus und filtert so nur die für Baden-Württemberg relevanten Neuerscheinungen heraus. Dies passiert ein mal wöchentlich. Zwei mal wöchentlich gleicht eMAS die von ihm erzeugte Liste mit dem Bestand der BLB im K10+ ab und entfernt die Titel aus seiner Liste, an denen die BLB bereits ein Exemplar hat.

In der Teaching Library gibt es einige Prozesse, die datenintensiv sind. Beispielsweise das Führen des Schulungsplans. Der Schulungsplan ist eine Tabelle, in der alle wichtigen Informationen zu geplanten und auch bereits durchgeführten Schulungen eines Jahres vermerkt sind. Der Plan enthält zum Beispiel Informationen über das Schulungsdatum, die Gruppengröße, Kontaktdaten zur Schule und zur begleitenden Lehrkraft, aber auch welche Art von Schulung gewünscht ist und ob es eventuelle Sonderwünsche gibt. Auch Organisatorisches wie zum Beispiel eine ausstehende Bestätigung des Schulungstermins durch die Lehrkraft oder bereitgestellte Schulungsmaterialien werden vermerkt. Da dieser Plan immer für ein ganzes Jahr geführt wird, entsteht hier eine sehr große Datenmenge.
Über diese Schulungen wird quartalsweise dann auch eine Statistik geführt und ausgewertet. Dies geschieht mithilfe von Excel-Tabellen und Google, da unsere Feedback-Formulare, die in die Auswertung mit einbezogen werden, über Google Docs erstellt wurden.
Ein Teil dieser Auswertung betrifft die Nutzungsstatistik unseres Online-Moduls, welches ich als Beispielprozess im nächsten Kapitel ausführlicher vorstellen werde.

Weitere datenintensive Prozesse in der BLB betreffen das Metadatenmanagement, bei dem oft große Mengen an Katalogisaten angepasst oder ergänzende Kategorien eingespielt werden. Vor Kurzem wurden beispielsweise im Projekt "Last copies BW" Listen mit allen Badischen Ortsnamen in möglichst allen möglichen Schreibweisen erstellt und diese mit der K10+-Datenbank abgeglichen. So konnten nachträglich eine sehr große Anzahl an badischen Pflichtexemplaren identifiziert werden. Diese badischen Pflichtexemplare konnten dann in einem gemeinsamen Prozess durch eine neue Kategorie gekennzeichnet werden.

Ein anderer Bereich, in dem datenintensive Prozesse aufkommen, ist der Bereich der Netzpublikationen, da hier E-Books zum Beispiel in großen Datenpaketen gekauft werden.

### Beispielprozess mit Verbesserungspotenzial
Als Beispielprozess, in dem ich Verbesserungspotenzial sehe, habe ich die Auswertung des Online-Lernmoduls der BLB in Moodle ausgewählt.
Diese Auswertung wird von mir einmal im Monat durchgeführt, es ist also ein regelmäßiger Prozess. Aktuell ist das Vorgehen so, dass ich in Moodle den Kurs auswähle, dessen Nutzung ich auswerten möchte und mir dann eine Datei über die gesamte Nutzung aller Gast-User seit Erstellung des Kurses ausgeben lasse. Bei den Dateiformaten gibt es eine Auswahl, ich nutze bisher immer Excel. In dieser Excel-Datei sind dann alle Schritte, die jeder Gast-User jemals in diesem Kurs gemacht hat als einzelne Zeilen aufgeführt. Je nach Nutzung können das mehrere zehntausend Zeilen pro Monat sein. Der erste Schritt ist nun, die Zeilen zu löschen, die den auszuwertenden Monat nicht betreffen. In Moodle gäbe es zwar theoretisch die Möglichkeit, einen bestimmten Monat für die Nutzungsstatistik auszuwählen, dies funktioniert in der Praxis jedoch nicht. 
Sind nun nur noch die Zeilen für den aktuellen Monat übrig, lösche ich die Spalten, die zur Auswertung nicht benötigt werden. Zum Beispiel sind dies die Uhrzeit der Nutzung oder welcher Schritt im Lernmodul ausgeführt wurde. Der letzte Schritt ist nun, die Dubletten in der Spalte mit den anonymisierten IP-Adressen der Nutzer zu löschen, sodass ich sehe, von wie vielen IP-Adressen auf das Modul zugegriffen wurde. Daraus schließe ich dann die annäherungsweisen Nutzungszahlen. Dies muss für jeden Kurs, für den man Nutzungszahlen möchte, einzeln durchgeführt werden.
Dieser Prozess ist trotz der Funktionen in Excel ziemlich zeitaufwändig und bietet daher ein großes Verbesserungspotenzial. 
Durch Python könnte man sich zum Beispiel direkt nur die Spalten der Tabelle anzeigen lassen, die man für die Auswertung auch tatsächlich braucht. Dies würde schon etwas Zeit sparen.
Auch eine Möglichkeit, in einem automatisierten Schritt die Zeilen zu löschen, die den aktuellen Monat nicht betreffen wäre eine große Hilfe.
Eine weitere Hilfe, diesen Prozess zu optimieren, wäre es, wenn man die einzelnen Tabellen für die einzelnen Kurse zusammenfügen und in einem Schritt auswerten könnte, sodass man dann nach den einzelnen Kursen filtern kann. Dies übersteigt jedoch mein aktuelles Wissen im IT-Bereich -- but the future is wide open! Sky is the limit.
